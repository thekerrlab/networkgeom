\documentclass[11pt, twocolumn]{article}
\usepackage[left=2.54cm, right=2.54cm, top=1.5cm]{geometry}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[skip=0pt, font=scriptsize,labelfont=scriptsize]{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{color} % text color for not taking
\usepackage{pdflscape}

\graphicspath{{figures/}}

\usepackage[
backend = biber,
style=ieee,
]{biblatex}
\addbibresource{neuronNetworkReferences.bib}

\newcommand{\code}[1]{\texttt{#1}}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

\usepackage{acro} % acronym package
\DeclareAcronym{STDP}{
	short = STDP,
	long  = Spike Time Dependent Plasticity,
}
\DeclareAcronym{MADELEINE}{
	short = MADELEINE,
	long  = 1959 seminal neural network,
}
\DeclareAcronym{CIFAR}{
	short = CIFAR,
	long  = Canadian Institute For Advanced Research,
}
\DeclareAcronym{NEURON}{
	short = NEURON,
	long  = Yale-developed neuron simulation environment,
}
\DeclareAcronym{NetPyNE}{
	short = NetPyNE,
	long  = ``Networks using Python and NEURON'' library,
}

\begin{document}
	\begin{titlepage} 
		\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here
		
		\center % Centre everything on the page
		
		%------------------------------------------------
		%	Headings
		%------------------------------------------------
		
		\textsc{\LARGE University of Sydney}\\[1.5cm] % Main heading such as the name of your university/college
		
		%\textsc{\Large Computation Neuronal Networks}\\[0.5cm] % Major heading such as course name
		
		%\textsc{\large PHYS2921}\\[0.5cm] % Minor heading such as course title
		
		%------------------------------------------------
		%	Title
		%------------------------------------------------
		
		\HRule\\[0.4cm]
		
		{\huge\bfseries Exploration of Computation Neuronal Network for Solving a Foraging Task}\\[0.4cm] % Title of your document
		
		\HRule\\[1.5cm]
		
		%------------------------------------------------
		%	Author(s)
		%------------------------------------------------
		
		%\begin{minipage}{0.4\textwidth}
		%	\begin{flushleft}
		%		\large
		%		\textit{Author}\\
		%		William .A. \textsc{Talbot} % Your name
		%	\end{flushleft}
		%\end{minipage}
		%~
		%\begin{minipage}{0.4\textwidth}
		%	\begin{flushright}
		%		\large
		%		\textit{Date}\\
		%		\textsc{} % Supervisor's name
		%	\end{flushright}
		%\end{minipage}
		
		% If you don't want a supervisor, uncomment the two lines below and comment the code above
		{\large\textit{Author}}\\
		William A. \textsc{Talbot}\\ % Your name
		{\large\textit{Supervisor}}\\
		Dr. Cliff \textsc{Kerr} % Your supervisor
		
		%------------------------------------------------
		%	Date
		%------------------------------------------------
		
		\vfill\vfill\vfill % Position the date 3/4 down the remaining page
		
		{\large May, 2019} % Date, change the \today to a set date if you want to be precise
		
		%------------------------------------------------
		%	Logo
		%------------------------------------------------
		
		%\vfill\vfill
		%\includegraphics[width=0.2\textwidth]{placeholder.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package
		
		%----------------------------------------------------------------------------------------
		
		\vfill % Push the date up 1/4 of the remaining page
		
	\end{titlepage}

\newpage
\twocolumn
%\tableofcontents

\section*{Abstract}

\section*{Introduction}

\subsection*{Neuroscience and the Rise of Neural Networks}
The development of modern artificial intelligence has its roots in the field of neuroscience since the inception of neural modelling in the 1943 with neuroscientist Warren McCulloch's and mathematician Walter Pitts' seminal paper on the ``logical calculus'' of ``nervous activity'' \cite{mcculloch1943logical}. Theories from neuroscience laid the foundations for successes in the following decades such as the first neural network with a real-world application, \acs{MADELEINE}, in 1959. The unsuccessful theory of ``Perceptron'' networks, ultimately proven limited in Minsky and Papert's 1969 book \cite{minsky1969perceptron}, was developed around the time and coupled with a cultural fear of robotics and AI stemming from science fiction, halted funding and progress. The mid 1980s saw a resurgence of the computational neuroscience field. Lacking digital means, several neural networks were simulated in analogue electrical circuits such as the parallel collective analog circuits of Hopfield and Tank's tackling of the travelling salesman problem \cite{hopfield1985neural} that improved on the previous two-state neuron approach. Their electrical circuits were biologically inspired, with standard electrical components such as amplifiers, capacitor and resistors used to model the neuronal dynamics. The problem, which aims to find a shortest-path circuit between points is well studied and is known to have exponential time complexity and be np-complete, however their circuit was able to produce excellent solutions in short time spans, rivalled only by the Lin-Kernighan Monte Carlo approach.

The core application of neural networks was realised at the time. It was noted in Hopfield and Tank's that ``A person ... quickly finds a very good path'' and that therefore, conceptually at least, it should be ``an easy problem''. The question raised is obvious - why is it that the human brain is able to quickly solve computationally difficult problems with relative ease, and is this replicable? The advances in robotics, and perceptual, pattern-intensive and data-dependent problems predicted \cite{hopfield1985neural} are evident and ongoing today. Noticeably in the field of neural networks after the 1980s, the balance between the biological principles of neuroscience and the mathematical constructs underlying the networks has shifted in favour of the latter. Today many such mathematical network models exist, such as feed-forward, recurrent, bi-directional recurrent, biological, spiking, convolutional, max-pooling convolutional, deep belief, self-delimiting and time delay neural networks \cite{schmidhuber2015deep}. Object classification is an example of a widely developed subset of neural net applications, however even today the best performances of these networks are sub-human and sometimes significantly worse. One recent convolutional neural network developed by Liang and Hu \cite{liang2015recurrent} trained on 50000 images of the 10-class \acs{CIFAR}-10 database achieved accuracies of less than 93\% while another, trained on 60000 images of the 100-class \acs{CIFAR}-100 database has a best accuracy of only 68.25\%. Not only is the accuracy of current artificial neural networks inferior to the human brain but also the size of the training set required to teach a neural network is disproportionately large comparatively. The potential for networks that require much smaller training sets is another motivator for investigating biologically realistic neural networks.

While research in the computational neuroscience certainly exists, it is much smaller than the artificial intelligence field and research into applied biological or spiking neural networks is even smaller. This is potentially a result of the lower observed performance of spiking neural networks for practical applications in comparison to the best traditional neural networks \cite{schmidhuber2015deep}. The combination of advances in the understanding of neuronal dynamics, powerful computational tools and demonstrations of computational viability \cite{zenke2014limits} has inspired some researchers around the world to return to modelling the human brain and investigate biological neural networks \cite{ashby2011tutorial}\cite{ashby2005frost}\cite{frank2005dynamic}\cite{hartley2006understanding}\cite{leveille2010running}. There are currently several well-known large-scale projects currently being developed. The most famous and longest-lasting is the Human Brain Project \cite{markram2015reconstruction} with its mission to build a novel and unified infrastructure for computational neuroscience. Another is ``BioSpawn'' \cite{eliasmith2016biospaun}, a dynamic brain simulation consisting of 2.5 million neurons and 8 billion connections comprised of visual input, motor output and memory models. It is based on the \acs{NEURON} simulation environment, a computational neuroscience tool that has been developed at Yale University for over 35 years. It is worth noting that the field of computational neuroscience is not limited to just the digital domain, but includes research done on real biological neuron networks, such as Frega et al.'s three-dimensional hippocampal network with embedded micro-transducer arrays which achieved a density of 80000 cells per cubic millimetre and an average of 600 synaptic connections per neuron \cite{frega2014network}.

The complex systems lab at the University of Sydney has also made significant developments in the field's digital side, with sensorimotor cortex models able to demonstrate reinforcement learning through spike time dependent plasticity (\acs{STDP}) in a virtual arm \cite{neymotin2013reinforcement}\cite{dura2017evolutionary}. Sanda et al.'s team at the University of California have similarly demonstrated effective \acs{STDP} reinforcement learning on a toy game where a sprite attempts to forage for food on a two-dimensional grid as efficiently as possible \cite{sanda2017multi}, similar in computational difficulty to the travelling salesman problem. This report will demonstrate an implementation of this network and investigate the effects of modifications to the network. This implementation will be done through the use of \acs{NetPyNE}, a tool for creating and running large-scale network simulations in \acs{NEURON} \cite{dura2018netpyne}.

\subsection*{Understanding Neurons and Spiking Neural Networks}
Understanding of the biochemistry and resultant dynamics of neurons, both alone and within neuronal populations, has accelerated in the past century. Models of neurons are used extensively within the software implemented and thus this report will provide an introduction to neuronal dynamics that underpin these models (sourced primarily from the \textit{Neuronal Dynamics} textbook \cite{gerstner2014neuronal}). The simple neuron consists of a central ``soma'' that acts as the non-linear processing unit of the cell, ``dendrites'', into which electric signals enter the cell, and the ``axon'' which is the output device of the cell. The dendrites are connected to the axons of other neurons using ``synapses'', of which there are many different types that enables neurons to have categorically different electrical characteristics depending on their purpose. In the human brain, neurons belong to populations of like neurons and often exist in layers, such as the cortex, approximately 3 millimetres deep on the outer surface of the cerebellum, where much sensory, motor and association processes occur.

The basic unit of signal transmission is the ``action potential'', a sharp voltage spike with a magnitude of approximately 100mV and typical duration of 1-2 milliseconds. When many spikes arrive at a soma from its dendrites, they accumulate and when the potential of the cell is high enough the neuron will produce an action potential of its own which travels along its axon to dendrites of other neurons. It is these through these signals that communication occurs between neurons and sophisticated behaviour is able to emerge. Gradually models have been developed to model the electrical characteristics of various neurons and the most prevalent is the Integrate-and-Fire models. The simplest is the ``Leaky'' Integrate-and-Fire model, where input is linearly integrated - the cell's potential $u(t)$ (also called membrane potential) is described by a linear differential equation which decays with some time constant $\tau$ and resets to 0 if it surpasses some threshold value $\vartheta$. This mathematical model can be simplified further by treating the action potential spikes as Dirac-delta pulses.
\begin{equation}
	\tau\frac{du}{dt} = -[u(t)-u_r]+RI(t)
	\label{eqn:leaky_integrate_and_fire_differential}
\end{equation}
\begin{equation}
	\text{if } u(t) > \vartheta \text{ then } \lim\limits_{\delta\leftarrow0;\delta>0}u(t+\delta) = u_r
	\label{eqn:leaky_integrate_and_fire_threshold}
\end{equation}

This model is of course an extremely simplified model of a neuron, and so far more sophisticated models, non-linear ``Generalised'' Integrate-and-Fire models, have been developed based on the empirical biophysical properties of neurons. This dates back to at least the 1950s with the Hodgkin-Huxley model of a giant squid's neuron that led to Hodgkin and Huxley's Nobel prize in 1963. The neuron membrane has hundreds of types of ion channels and this rich biophysics leads to much nuance in neuron electrical behaviour. This includes hyper-polarisation of the cell and refractory periods of suppressed firing, spike-frequency adaptation, sub-threshold effects and post-inhibitory rebound. Exponential and quadratic Integrate-and-Fire models with adaptation and stochastic variables are some examples of non-linear models that have been reasonably fit to experimental data. When these models are used for their appropriate class of simulated neurons, we are able to generate networks that exhibit biologically realistic behaviour. It is important to introduce at this point the concept of inhibition in neuronal networks. Inhibitory neurons, unlike excitatory neurons which have been discussed so far, produce action potentials that decrease the membrane potential of the receiving neuron rather than increase it, meaning that the receiving neuron must receive more excitatory input in order to overcome its threshold and fire compared to what it normally would. Inhibitory neurons maintain balance in a network, preventing it from becoming over-stimulated or ``epileptic''. It is with populations of excitatory and inhibitory neurons that  biological, spiking neural networks can be created.

The final major component of the neural network model is how it is able to be modified over time. The approach taken is reinforcement learning through spike time dependent plasticity (\acs{STDP}). \acs{STDP} is simply the increasing of the strength of a connection if the input, or pre-synaptic spike to a neuron is followed by a post-synaptic spike, also called a ``pre before post'' event \cite{sanda2017multi}. In unsupervised \acs{STDP}, whenever this occurs the connection between the respective neurons is increased, and conversely if a ``post before pre'' event occurs the connection is weakened. This report will utilise a form of reinforcement learning \acs{STDP} mechanism, whereby the strengthening or weakening of a connection that experiences a ``pre before post'' event is delayed and the selection of reward or punishment is chosen based on a heuristic.

\section*{Methods}
\subsection*{The Foraging Problem and Network Structure}
The details of the foraging problem are almost identical to that of Sanda et al.'s implementation \cite{sanda2017multi}, in which ``epochs'' of 300 milliseconds with a 0.5 millisecond timestep divided up the simulation time. The virtual environment was composed of a 49 by 49 occupancy grid containing some density of randomly scattered food. At the end of each epoch, the virtual sprite moved one square in one of the eight compass directions and if any food occupied that square, it was ``gathered'' and another food item was placed randomly on the map to maintain constant density. Each epoch lasted enough time for the neural network to receive input stimuli, process this stimuli and produce an output. The neural network itself contained three layers of Izhikevich regular spiking pyramidal cell neurons \cite{izhikevich2007dynamical}\cite{izhikevich2008large}; an 7 by 7 input layer (I), a 28 by 28 middle layer (M) and 3 by 3 output layer (O). The input layer which provided the only stimulus to the network is related to the 7 by 7 area around the virtual sprite, such that at each epoch, only the neurons in this layer that corresponded to a food-occupied grid location were stimulated. Thus, the ``middle'' neuron of this layer corresponding to the virtual sprite was never stimulated, 8 neurons of the layer corresponded to the inner circle around the sprite, 16 corresponded to one move further out and 24 corresponded to the outermost circle of occupancy in the visual field of the sprite. Each of these input layer neurons had uniform weight excitatory connections to 9 randomly selected middle layer neurons, and each of these middle layer neurons are connected to every output layer neuron with weights initially drawn from a normal distribution. The output layer neurons correspond to a compass direction with the middle neuron unused. The highest spiking neuron of the output neurons was used as the direction, and pseudo-random numbers were generated to break ties. Additionally to prevent movement cycles in the learning process, a 1\% chance was introduced for a random direction to be chosen irrespective of activity in the output layer.

\subsection*{Implementing \acs{STDP}}
Rewarded spike time dependent plasticity (\acs{STDP}) was implemented between the middle layer neurons and output neurons such that at the end of each epoch, the sprite moved and if food was gathered then the synaptic connections which had experienced ``pre before post'' activity were strengthened. If food was not gathered, then these connections were weakened, however since not gathering food is much more likely than gathering food, this punishment was set to be -0.1 times that of the reward case. The model for spike time dependent plasticity was taken from a model of reinforcement learning for a two-joint virtual arm \cite{neymotin2013reinforcement} \cite{chadderdon2012reinforcement}, as was the algorithmic structure of fixed frequency update calls within the NetPyNE simulation. However \acs{STDP} alone is insufficient to train a network, and so synaptic balancing mechanisms, random variability and inhibition were used in order to obtain above-chance level results.

\subsection*{Synaptic Balancing Mechanisms}
In total four synaptic balancing mechanisms were used to obtain above-chance gathering rate performance. Without any of them the network tended to some extreme of synaptic activity that did not allow for learning to occur.

\subsubsection*{1. Hetero-synaptic Balancing}
In both experimental studies and detailed biological models it has been shown that the sum of input synapse weights to any cell must be held approximately constant in order to prevent runaway spiking dynamics \cite{sanda2017multi}. Therefore a simple rule was implemented such that whenever a single input synapse's weight was adjusted by an \acs{STDP} reward or punishment, all other input synapses were adjusted to compensate and thus constant synaptic input to each cell was maintained. Due to the implementation of frequency targeting, this constant synaptic input is in fact a very slowly changing variable that depends on the firing frequencies of the output neurons.

\subsubsection*{2. Frequency Targeting}
It was found that the spiking frequency of the output neurons was immensely important on decision making \cite{sanda2017multi}. When spiking frequency of the output layer was low ($<1$ Hz), the number of epochs with zero spikes were high as excitability was insufficient to reach the spiking threshold. In order to avoid these lengths of silent output epochs, it was desired that the overall spiking frequency of the output layer was high, however increasing the output layer excitability too high resulted in epochs where all the output cells spiked, and some multiple times, thus increasing the number of non-zero ties. Hence a frequency of 1.6 Hz was chosen as a default output firing rate as a good balancing point between silent epochs and high-spiking spike-tied epochs. In order to achieve this desired firing frequency, the excitatory weight sum was gradually adjusted using a slow-moving variable that represented the target synaptic weight $W_T$ of the cell. If the particular output cell was firing under the desired frequency, this variable was increased and if it was over-firing this variable was decreased by $\Delta_W$ as per equation \ref{eqn:frequency_targeting}.
\begin{equation}
	W_T(n+1) =
	\begin{cases} 
	W_T(n)\cdot(1+\Delta_W) & f_{spike} < f_{target} \\
	W_T(n)\cdot(1-\Delta_W) & f_{spike} > f_{target}
	\end{cases}
	\label{eqn:frequency_targeting}
\end{equation}

\subsubsection*{3. Output Balancing}
Previous work by the authors of the paper upon which this project is based \cite{skorheim2014spiking} revealed that balancing the weights of output synapses helped prevent a several neurons controlling the whole network and others from dying off entirely. This was implemented by dividing the \acs{STDP} reward by a normalising ratio $R_n$, equal to the current synpatic output sum divided by the initial synaptic output sum for each cell (equation \ref{eqn:output_balancing}).
\begin{equation}
	R_n = \frac{\sum W_{curr}}{\sum W_{init}}
	\label{eqn:output_balancing}
\end{equation}
As a result already strengthened neurons were less able to increase in weight compared to weaker neurons, giving the later an opportunity to recover and an advantage over the already dominating neurons.

\subsubsection*{4. Soft Thresholding}
The final synaptic balancing is a method called ``soft thresholding'' which was in-built into the \acs{STDP} model used. This mechanism is similar to output balancing in that it adds another multiplicative factor to the synaptic reward or punishment that depends not on any other synaptic connection weights but on a chosen maximum weight. As the synaptic weight increases towards this value, this ratio $S$ for positive rewards approaches 0 and 1 for punishments as per equation \ref{eqn:soft_thresholding}. As the weight decreases towards zero, the inverse of this relation is true, and so no weight can ever reach 0 or some maximum weight (set to 10 times the average starting excitatory weight) by the \acs{STDP} mechanism.
\begin{equation}
	S = \quad
	\begin{cases} 
	(1-\frac{W}{W_{max}}) & \text{ if rewarding} \\
	\frac{W}{W_{max}} & \text{if punishing}
	\end{cases}
	\label{eqn:soft_thresholding}
\end{equation}


\subsection*{Random Variability}
Noise and random variability is an omnipresent component of almost any neural network and allows random outputs to occur for a given input, which may or may not be rewarded. If this is able to occur in some way several times then it is likely that the synapse's strength will surpass its peers and if ``correct'' is much more likely to strengthen further, while if not, is likely to fall in strength back to average or lower. Random variability was introduced into the system in several ways. The initial weights of the excitatory connections were drawn from the absolute value of a normal distribution with 0.5\% variance. Additionally the planar coordinates of each layer ($x$ and $z$ coordinates) were drawn from a uniformly random distribution within a fixed square and the layers separated along the $y$ axis by 100 $\micro$m. The action potentials traveled between connected neurons with a propagation velocity of 100 $\micro$m/ms and thus a random geometrical arrangement enabled variability in the arrival of action potential signals.

\subsection*{Inhibition}
A simple inhibition model was used in this simulation based on the model employed by Sanda et al. \cite{sanda2017multi} whereby each excitatory connection between the middle and output layers was paired with an inhibitory connection with roughly the same net weight which was essential in preventing over-stimulation of the output layer. It was essential that the weight of the inhibitory connections was carefully tuned to be under the net final excitatory weight since over-inhibition led to silent epochs while under-inhibition achieved epochs with many non-zero ties. \acs{NetPyNE} is very capable of creating populations of inhibitory neurons and implementing a middle layer with mixed excitatory and inhibitory neurons would be of interest for further study as a more biologically realistic neuronal network model.

\section*{Results}

\section*{Discussion}

\section*{Conclusion}

\printacronyms[name=Acronyms]
\printbibliography{}

\section*{Contribution and Reflection}

\end{document}