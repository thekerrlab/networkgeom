\documentclass[11pt, twocolumn]{article}
\usepackage[left=2.54cm, right=2.54cm, top=1.5cm]{geometry}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage[skip=0pt, font=scriptsize,labelfont=scriptsize]{caption}
\usepackage{subcaption}
\usepackage{float}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{mathtools}
\usepackage{siunitx}
\usepackage{textcomp}
\usepackage{gensymb}
\usepackage{color} % text color for not taking
\usepackage{pdflscape}

\graphicspath{{figures/}}

\usepackage[
backend = biber,
style=ieee,
]{biblatex}
\addbibresource{neuronNetworkReferences.bib}

\newcommand{\code}[1]{\texttt{#1}}
\DeclarePairedDelimiter\abs{\lvert}{\rvert}%

\usepackage{acro} % acronym package
\DeclareAcronym{STDP}{
	short = STDP,
	long  = Spike Time Dependent Plasticity,
}

\begin{document}
	\begin{titlepage} 
		\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for horizontal lines, change thickness here
		
		\center % Centre everything on the page
		
		%------------------------------------------------
		%	Headings
		%------------------------------------------------
		
		\textsc{\LARGE University of Sydney}\\[1.5cm] % Main heading such as the name of your university/college
		
		%\textsc{\Large Computation Neuronal Networks}\\[0.5cm] % Major heading such as course name
		
		%\textsc{\large PHYS2921}\\[0.5cm] % Minor heading such as course title
		
		%------------------------------------------------
		%	Title
		%------------------------------------------------
		
		\HRule\\[0.4cm]
		
		{\huge\bfseries Exploration of Computation Neuronal Network for Solving a Foraging Task}\\[0.4cm] % Title of your document
		
		\HRule\\[1.5cm]
		
		%------------------------------------------------
		%	Author(s)
		%------------------------------------------------
		
		%\begin{minipage}{0.4\textwidth}
		%	\begin{flushleft}
		%		\large
		%		\textit{Author}\\
		%		William .A. \textsc{Talbot} % Your name
		%	\end{flushleft}
		%\end{minipage}
		%~
		%\begin{minipage}{0.4\textwidth}
		%	\begin{flushright}
		%		\large
		%		\textit{Date}\\
		%		\textsc{} % Supervisor's name
		%	\end{flushright}
		%\end{minipage}
		
		% If you don't want a supervisor, uncomment the two lines below and comment the code above
		{\large\textit{Author}}\\
		William A. \textsc{Talbot}\\ % Your name
		{\large\textit{Supervisor}}\\
		Dr. Cliff \textsc{Kerr} % Your supervisor
		
		%------------------------------------------------
		%	Date
		%------------------------------------------------
		
		\vfill\vfill\vfill % Position the date 3/4 down the remaining page
		
		{\large May, 2019} % Date, change the \today to a set date if you want to be precise
		
		%------------------------------------------------
		%	Logo
		%------------------------------------------------
		
		%\vfill\vfill
		%\includegraphics[width=0.2\textwidth]{placeholder.jpg}\\[1cm] % Include a department/university logo - this will require the graphicx package
		
		%----------------------------------------------------------------------------------------
		
		\vfill % Push the date up 1/4 of the remaining page
		
	\end{titlepage}

\newpage
\twocolumn
\tableofcontents
\printacronyms[name=Acronyms]
\section*{Abstract}

\section*{Introduction}

\subsection*{Neuroscience and the Rise of Neural Networks}
The development of modern artificial intelligence has its roots in the field of neuroscience since the inception of neural modelling in the 1943 with neuroscientist Warren McCulloch's and mathematician Walter Pitts' seminal paper on the ``logical calculus'' of ``nervous activity'' \cite{mcculloch1943logical}. Theories from neuroscience laid the foundations for successes in the following decades such as the first neural network with a real-world application, MADELEINE, in 1959. The unsuccessful theory of ``Perceptron'' networks, ultimately proven limited in Minsky and Papert's 1969 book \cite{minsky1969perceptron}, was developed around the time and coupled with a cultural fear of robotics and AI stemming from science fiction, halted funding and progress. The mid 1980s saw a resurgence of the computational neuroscience field. Lacking digital means, several neural networks were simulated in analogue electrical circuits such as the parallel collective analog circuits of Hopfield and Tank's tackling of the travelling salesman problem \cite{hopfield1985neural} that improved on the previous two-state neuron approach. Their electrical circuits were biologically inspired, with standard electrical components such as amplifiers, capacitor and resistors used to model the neuronal dynamics. The problem, which aims to find a shortest-path circuit between points is well studied and is known to have exponential time complexity and be np-complete, however their circuit was able to produce excellent solutions in short time spans, rivalled only by the Lin-Kernighan Monte Carlo approach.

The core application of neural networks was realised at the time. It was noted in Hopfield and Tank's that ``A person ... quickly finds a very good path'' and that therefore, conceptually at least, it should be ``an easy problem''. The question raised is obvious - why is it that the human brain is able to quickly solve computationally difficult problems with relative ease, and is this replicable? The advances in robotics, and perceptual, pattern-intensive and data-dependent problems predicted \cite{hopfield1985neural} are evident and ongoing today. Noticeably in the field of neural networks after the 1980s, the balance between the biological principles of neuroscience and the mathematical constructs underlying the networks has shifted in favour of the latter. Today many such mathematical network models exist, such as feed-forward, recurrent, bi-directional recurrent, biological, spiking, convolutional, max-pooling convolutional, deep belief, self-delimiting and time delay neural networks \cite{schmidhuber2015deep}. Object classification is an example of a widely developed subset of neural net applications, however even today the best performances of these networks are sub-human and sometimes significantly worse. One recent convolutional neural network developed by Liang and Hu \cite{liang2015recurrent} trained on 50000 images of the 10-class CIFAR-10 database achieved accuracies of less than 93\% while another, trained on 60000 images of the 100-class CIFAR-100 database has a best accuracy of only 68.25\%. Not only is the accuracy of current artificial neural networks inferior to the human brain but also the size of the training set required to teach a neural network is disproportionately large comparatively. The potential for networks that require much smaller training sets is another motivator for investigating biologically realistic neural networks.

While research in the computational neuroscience certainly exists, it is much smaller than the artificial intelligence field and research into applied biological or spiking neural networks is even smaller. This is potentially a result of the lower observed performance of spiking neural networks for practical applications in comparison to the best traditional neural networks \cite{schmidhuber2015deep}. The combination of advances in the understanding of neuronal dynamics, powerful computational tools and demonstrations of computational viability \cite{zenke2014limits} has inspired some researchers around the world to return to modelling the human brain and investigate biological neural networks \cite{ashby2011tutorial}\cite{ashby2005frost}\cite{frank2005dynamic}\cite{hartley2006understanding}\cite{leveille2010running}. There are currently several well-known large-scale projects currently being developed. The most famous and longest-lasting is the Human Brain Project \cite{markram2015reconstruction} with its mission to build a novel and unified infrastructure for computational neuroscience. Another is ``BioSpawn'' \cite{eliasmith2016biospaun}, a dynamic brain simulation consisting of 2.5 million neurons and 8 billion connections comprised of visual input, motor output and memory models. It is based on the NEURON simulation environment, a computational neuroscience tool that has been developed at Yale University for over 35 years. It is worth noting that the field of computational neuroscience is not limited to just the digital domain, but includes research done on real biological neuron networks, such as Frega et al.'s three-dimensional hippocampal network with embedded micro-transducer arrays which achieved a density of 80000 cells per cubic millimetre and an average of 600 synaptic connections per neuron \cite{frega2014network}.

The complex systems lab at the University of Sydney has also made significant developments in the field's digital side, with sensorimotor cortex models able to demonstrate reinforcement learning through spike time dependent plasticity (\acs{STDP}) in a virtual arm \cite{neymotin2013reinforcement}\cite{dura2017evolutionary}. Sanda et al.'s team at the University of California have similarly demonstrated effective \acs{STDP} reinforcement learning on a toy game where a sprite attempts to forage for food on a two-dimensional grid as efficiently as possible \cite{sanda2017multi}, similar in computational difficulty to the travelling salesman problem. This report will demonstrate an implementation of this network and investigate the effects of modifications to the network. This implementation will be done through the use of NetPyNe, a tool for creating and running large-scale network simulations in NEURON \cite{dura2018netpyne}.

\subsection*{Understanding Neurons and Spiking Neural Networks}
Understanding of the biochemistry and resultant dynamics of neurons, both alone and within neuronal populations, has accelerated in the past century. Models of neurons are used extensively within the software implemented and thus this report will provide an introduction to neuronal dynamics that underpin these models (sourced primarily from the \textit{Neuronal Dynamics} textbook \cite{gerstner2014neuronal}). The simple neuron consists of a central ``soma'' that acts as the non-linear processing unit of the cell, ``dendrites'', into which electric signals enter the cell, and the ``axon'' which is the output device of the cell. The dendrites are connected to the axons of other neurons using ``synapses'', of which there are many different types that enables neurons to have categorically different electrical characteristics depending on their purpose. In the human brain, neurons belong to populations of like neurons and often exist in layers, such as the cortex, approximately 3 millimetres deep on the outer surface of the cerebellum, where much sensory, motor and association processes occur.

The basic unit of signal transmission is the ``action potential'', a sharp voltage spike with a magnitude of approximately 100mV and typical duration of 1-2 milliseconds. When many spikes arrive at a soma from its dendrites, they accumulate and when the potential of the cell is high enough the neuron will produce an action potential of its own which travels along its axon to dendrites of other neurons. It is these through these signals that communication occurs between neurons and sophisticated behaviour is able to emerge. Gradually models have been developed to model the electrical characteristics of various neurons and the most prevalent is the Integrate-and-Fire models. The simplest is the ``Leaky'' Integrate-and-Fire model, where input is linearly integrated - the cell's potential $u(t)$ (also called membrane potential) is described by a linear differential equation which decays with some time constant $\tau$ and resets to 0 if it surpasses some threshold value $\vartheta$. This mathematical model can be simplified further by treating the action potential spikes as Dirac-delta pulses.
\begin{equation}
	\tau\frac{du}{dt} = -[u(t)-u_r]+RI(t)
	\label{eqn:leaky_integrate_and_fire_differential}
\end{equation}
\begin{equation}
	\text{if } u(t) > \vartheta \text{ then } \lim\limits_{\delta\leftarrow0;\delta>0}u(t+\delta) = u_r
	\label{eqn:leaky_integrate_and_fire_threshold}
\end{equation}

This model is of course an extremely simplified model of a neuron, and so far more sophisticated models, non-linear ``Generalised'' Integrate-and-Fire models, have been developed based on the empirical biophysical properties of neurons. This dates back to at least the 1950s with the Hodgkin-Huxley model of a giant squid's neuron that led to Hodgkin and Huxley's Nobel prize in 1963. The neuron membrane has hundreds of types of ion channels and this rich biophysics leads to much nuance in neuron electrical behaviour. This includes hyper-polarisation of the cell and refractory periods of suppressed firing, spike-frequency adaptation, sub-threshold effects and post-inhibitory rebound. Exponential and quadratic Integrate-and-Fire models with adaptation and stochastic variables are some examples of non-linear models that have been reasonably fit to experimental data. When these models are used for their appropriate class of simulated neurons, we are able to generate networks that exhibit biologically realistic behaviour. It is important to introduce at this point the concept of inhibition in neuronal networks. Inhibitory neurons, unlike excitatory neurons which have been discussed so far, produce action potentials that decrease the membrane potential of the receiving neuron rather than increase it, meaning that the receiving neuron must receive more excitatory input in order to overcome its threshold and fire compared to what it normally would. Inhibitory neurons maintain balance in a network, preventing it from becoming over-stimulated or ``epileptic''. It is with populations of excitatory and inhibitory neurons that  biological, spiking neural networks can be created.

The final major component of the neural network model is how it is able to be modified over time. The approach taken is reinforcement learning through spike time dependent plasticity (\acs{STDP}). \acs{STDP} is simply the increasing of the strength of a connection if the input, or pre-synaptic spike to a neuron is followed by a post-synaptic spike, also called a ``pre before post'' event \cite{sanda2017multi}. In unsupervised \acs{STDP}, whenever this occurs the connection between the respective neurons is increased, and conversely if a ``post before pre'' event occurs the connection is weakened. This report will utilise a form of reinforcement learning \acs{STDP} mechanism, whereby the strengthening or weakening of a connection that experiences a ``pre before post'' event is delayed and the selection of reward or punishment is chosen based on a heuristic.

\section*{Methods}
\subsection*{The Foraging Problem and Network Structure}
The details of the foraging problem are almost identical to that of Sanda et al.'s implementation \cite{sanda2017multi}, in which ``epochs'' of 300 milliseconds with a 0.5 millisecond timestep divided up the simulation time. The virtual environment was composed of a 49 by 49 occupancy grid containing some density of randomly scattered food. At the end of each epoch, the virtual sprite moved one square in one of the eight compass directions and if any food occupied that square, it was ``gathered'' and another food item was placed randomly on the map to maintain constant density. Each epoch lasted enough time for the neural network to receive input stimuli, process this stimuli and produce an output. The neural network itself contained three layers; an 7 by 7 input layer (I), a 28 by 28 middle layer (M) and 3 by 3 output layer (O). The input layer which provided the only stimulus to the network is related to the 7 by 7 area around the virtual sprite, such that at each epoch, only the neurons in this layer that corresponded to a food-occupied grid location were stimulated. Thus, the ``middle'' neuron of this layer corresponding to the virtual sprite was never stimulated, 8 neurons of the layer corresponded to the inner circle around the sprite, 16 corresponded to one move further out and 24 corresponded to the outermost circle of occupancy in the visual field of the sprite. Each of these input layer neurons had uniform weight excitatory connections to 9 randomly selected middle layer neurons, and each of these middle layer neurons are connected to every output layer neuron with weights initially drawn from a normal distribution. The output layer neurons correspond to a compass direction with the middle neuron unused. The highest spiking neuron of the output neurons was used as the direction, and pseudo-random numbers were generated to break ties. Additionally to prevent movement cycles in the learning process, a 1\% chance was introduced for a random direction to be chosen irrespective of activity in the output layer.

\subsection*{Implementing \acs{STDP}}

\subsection*{Synaptic Balancing Mechanisms}
In total \colorbox{red}{X} synaptic balancing mechanisms were used to obtain above-chance gathering rate performance.
\subsubsection*{1. Heterosynaptic Balancing}
\subsubsection*{2. Frequency Targeting}

\section*{Results}

\section*{Discussion}

\section*{Conclusion}

\printbibliography{}

\section*{Contribution and Reflection}

\end{document}