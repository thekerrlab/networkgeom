1. Title -- maybe "Exploration of a Computational Neuronal Network for Solving a Foraging Task"?

2. Abstract -- maybe not important to mention NetPyNE here, also don't need to say "simple" twice

3. Abstract -- maybe say "reinforcement learning and spike-timing...", since STDP is separate from RL.

4. p. 1, "in the 1970's suppressing" -> "in the 1970s suppressed" (either 1970's or 1970s is fine, but you use the latter later)

5. p. 1, "well-studied problem which aims to find a" -> "well-studied problem of finding"

6. p. 1, "best performances are sub-human"...I don't think that's true, see e.g. https://venturebeat.com/2017/12/08/6-areas-where-artificial-neural-networks-outperform-humans/

7. p. 1, "despite their computational feasibility" -- I mean, they tend to be less computationally feasible, which is precisely why they're not used as much...

8. p. 1, "BioSpawn" -> "BioSpaun"

9. p. 2, "STDP reinforcement learning" -> "STDP-based reinforcement learning"

10. p. 2, "where much sensory" -> "where many sensory"

11. p. 2, Should be consistent with units, e.g. "mV" and "ms" or "millivolts" and "milliseconds"

12. p. 2, "It is these through these" -> "It is through these"

13. p. 2, Usually potential is indicated by $v$, not $u$? But OK. Also, you don't want to include the actual Izhikevich equations?

14. p. 2, Integrate-and-fire is distinct from Hodgkin-Huxley, see e.g. https://iopscience.iop.org/article/10.1088/0305-4470/34/8/311 or https://www.ncbi.nlm.nih.gov/pubmed/16622699

15. p. 3, "an 7x7" -> "a 7x7"

16. p. 3, Usually good to refer to figures in the text, e.g. "The neural network ... as shown in Figure 2"

17. p. 4, "Pseudo-random" -> "pseudorandom"

18. p. 5, "0.5% variance" -- are you sure you mean %? That's tiny...

19. p. 5, "NetPyNe is very capable..." -- this doesn't read well, I would rephrase or remove this sentence.

20. p. 6, "return back to visited locations just as often" -- wouldn't there be a roughly 1 in 8 chance of revisiting a location on each step? It would be a bit higher than that but shouldn't be 1 in 2, should it...? Here I think it's important to mention that you did run it without learning (Supplemental Figure 9) and the performance was...0.056 or something? In case the reader doesn't buy your logical argument :)

21. p. 6, Figure 4, awesome :D

22. p. 6, I think you need to explain Figure 5 more, since this is basically your key result. Also, I'm not convinced by the capitalization of your figure captions, would kind of prefer sentence case, but up to you :)

23. p. 10, If you can save Fig. 13 properly rather than a screenshot, it'd be better :P